{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Learning handwritten digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/mnist/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/mnist/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/mnist/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/mnist/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from IPython.display import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "sns.set_context(\"poster\")\n",
    "sns.set_style('white', {'axes.linewidth': 0, 'xtick.major.size': 0.0,\n",
    " 'xtick.minor.size': 0.0, 'ytick.major.size': 0.0,\n",
    " 'ytick.minor.size': 0.0,\n",
    " 'figure.figsize': (10, 6)})\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "\n",
    "\n",
    "data_dir = '/tmp/mnist'\n",
    "mnist = input_data.read_data_sets(data_dir, one_hot=True)\n",
    "train_labels = np.argmax(mnist.train.labels, axis=1)\n",
    "train_images = mnist.train.images.reshape(55000, 28, 28)\n",
    "\n",
    "def view_heatmap(image, label=\"\"):\n",
    "    \"\"\" Plots a grayscale heatmap \"\"\"\n",
    "    if label:\n",
    "        plt.title('Label is {label}'.format(label=label))\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    cur_axes = plt.gca()\n",
    "    cur_axes.axes.get_xaxis().set_visible(False)\n",
    "    cur_axes.axes.get_yaxis().set_visible(False)from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Do you recognize this number?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOcAAADnCAYAAADl9EEgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAABpRJREFUeJzt3b1vT/8bx/HPp7GYtTExSmsrwdSkK2PD4g9wM7hJTOpmQDBVTJJ2dDNWTcIk7UhsUjqpSdJ2YxP9br+p5zrR6q+vo4/H6MqbgzydxJVzTn99fb0H5BnY6QsANiZOCCVOCCVOCCVOCLWnZe6/cmH79Tf6QXdOCCVOCCVOCCVOCCVOCCVOCCVOCCVOCCVOCCVOCCVOCCVOCCVOCCVOCCVOCCVOCCVOCCVOCCVOCCVOCCVOCCVOCCVOCCVOCCVOCCVOCCVOCCVOCCVOCCVOCCVOCCVOCCVOCCVOCCVOCCVOCCVOCCVOCLVnpy+AP7O8vFzOZ2Zmyvn9+/fLeb/fb5ytr6+XZ0dGRsr53bt3y/nExEQ5323cOSGUOCGUOCGUOCGUOCGUOCGUOCFUv2V3VS+22JSVlZXG2YMHD8qzz58/L+dra2vlvG1XuZU9Z3W21+v1Dhw4UM7fv3/fOBscHCzPdtyGf3DunBBKnBBKnBBKnBBKnBBKnBDKKmUb3Lt3r5zfvn27cda2jtjudcbQ0FA5r6yurpbzr1+/lvPDhw83zj59+rSZS+oKqxToEnFCKHFCKHFCKHFCKHFCKHFCKHvObXDs2LFy/vHjx8bZVvecba+nfPfuXTnfyqNZCwsL5Xx8fLycV7/3X79+beaSusKeE7pEnBBKnBBKnBBKnBBKnBBKnBDKnnMTFhcXy/nx48fL+b59+xpnbc9Ttu0hp6amyvnjx4/L+eTkZOPs4MGD5dk2bTvcgYHme8WTJ0/Ks+fOndvUNYWw54QuESeEEieEEieEEieEEieEEieEsufcBp8/fy7n1a5yq5+6m56eLucXL14s59Vn+I4cOVKenZ2dLednzpwp59Ue9Pv37+XZjn8i0J4TukScEEqcEEqcEEqcEEqcEEqcEGrPTl/Av2h4eHjHfu22fd+hQ4fKefWs6aNHj8qzDx8+LOdt79zdzv1vF7lzQihxQihxQihxQihxQihxQiirlB0wPz/fONvK42a9XvsnAJeWlsr5iRMnGmcrKyvl2bZXX7a99vP169flfLdx54RQ4oRQ4oRQ4oRQ4oRQ4oRQ4oRQ9pw74MWLF42zmZmZ8mzbY1dtu8a289UucyuPfPV6vd6lS5fKedurN3cbd04IJU4IJU4IJU4IJU4IJU4IJU4IZc8Zpm1PuZPnx8bGyrNTU1Pl3B7zz7hzQihxQihxQihxQihxQihxQihxQih7zh1w9uzZxtny8nJ5dnV1tZy3vff258+f5bxy586dcm6P+Xe5c0IocUIocUIocUIocUIocUIocUKofsu7SOsXlRKnbc958+bNcj43N9c4Gx0dLc+2fV+z7b22u9iGD9G6c0IocUIocUIocUIocUIocUKof3aVUn3Kbmho6P94Jd1y8uTJxtmbN2/Ks22vxrx69eqmrmkXsEqBLhEnhBInhBInhBInhBInhBInhOrsqzHn5+fL+bVr1xpnw8PD5dmnT59u6pr+BZOTk42zt2/flme/fPnyty9nV3PnhFDihFDihFDihFDihFDihFDihFCxe87qecxer9c7f/58Od+/f3/jbDfvMX/8+FHOL1y40DhrefaXv8ydE0KJE0KJE0KJE0KJE0KJE0KJE0LF7jlfvnxZzpeWlsr5+Pj4X7ya7lhcXCznp0+fLufVM5n9/oavV/2ftudk+TPunBBKnBBKnBBKnBBKnBBKnBAqdpUyNjZWzn///l3Oq1dnPnv2rDw7MjJSzo8ePVrO2ywvLzfOFhYWyrOzs7Pl/NWrV+W87bGval1y5cqV8mzbnD/jzgmhxAmhxAmhxAmhxAmhxAmhxAmh+i17r9h3IbY9+jQ3N9c428qur9fr9UZHR8t5m2/fvjXO1tbWyrNbvfa28zdu3GicXb58uTw7ODhYzmm04V+aOyeEEieEEieEEieEEieEEieEEieE6uyes+0TgadOnWqcffjwoTw7MFD/m7Wdu8a2s3v37i3nbc+iXr9+vZxPTEyUc7aFPSd0iTghlDghlDghlDghlDghlDghVGf3nG1WV1cbZ7du3drSzz09PV3O23aFW3nuse3dsD7D10n2nNAl4oRQ4oRQ4oRQ4oRQ4oRQ4oRQ/+yeEzrEnhO6RJwQSpwQSpwQSpwQSpwQSpwQSpwQSpwQSpwQSpwQSpwQSpwQSpwQSpwQSpwQSpwQSpwQSpwQSpwQSpwQSpwQak/LfMNX9gHbz50TQokTQokTQokTQokTQokTQv0HRp89J5KhszQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fab98bf9b38>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "view_heatmap(255 - train_images[1]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Common algorithms\n",
    "* K-nearest neighbours (next lecture)\n",
    "* **Multi class logistic regression**\n",
    "* Fully connected neural network network\n",
    "* Convolutional neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi class logistic regression\n",
    "\n",
    "![](img/softmax-regression-scalargraph.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The multi class logistic regression model generalizes logistic regression to multiple classes.  \n",
    "The model hypothesis of multi class logistic regression with $C$ classes is\n",
    "$$\n",
    "\\begin{align}\n",
    "h_\\theta(X) &= X \\theta \\,, \\\\\n",
    "z &= X \\theta + \\theta_0 \\,, \\\\ \n",
    "g_j(z) &= \\frac{e^{z_j}}{\\sum_{k=1}^C e^{z_k}} \\,.\n",
    "\\end{align}\n",
    "$$\n",
    "This model satisfies the following constraints:\n",
    "$$\n",
    "\\begin{align}\n",
    "& 0 \\leq  h_{\\theta, j}(X) \\leq 1 \\,, \\\\\n",
    "& \\sum_{j=1}^C h_{\\theta, j}(X) \\leq 1 = 1\\,. \\\\\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "A suitable loss function for multi class classification, is cross entropy\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "& J(\\theta) = -\\sum_{i=1}^N \\sum_{j=1}^C y_i \\log(h_{j,\\theta}(x_i) \\,.\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "In this tutorial we are going to implement and train this model with TensorFlow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple softmax regression\n",
    "Based on tutorial [mnist for beginners](https://www.tensorflow.org/versions/r1.1/get_started/mnist/beginners) by TensorFlow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9214\n"
     ]
    }
   ],
   "source": [
    "# Create the model\n",
    "x = tf.placeholder(tf.float32, [None, 784])\n",
    "W = tf.Variable(tf.zeros([784, 10]))\n",
    "b = tf.Variable(tf.zeros([10]))\n",
    "y = tf.matmul(x, W) + b\n",
    "\n",
    "# Define loss and optimizer\n",
    "y_ = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "# The raw formulation of cross-entropy,\n",
    "#\n",
    "#   tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(tf.nn.softmax(y)),\n",
    "#                                 reduction_indices=[1]))\n",
    "#\n",
    "# can be numerically unstable.\n",
    "#\n",
    "# So here we use tf.nn.softmax_cross_entropy_with_logits on the raw\n",
    "# outputs of 'y', and then average across the batch.\n",
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=y_, logits=y))\n",
    "train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "tf.global_variables_initializer().run()\n",
    "# Train\n",
    "for _ in range(1000):\n",
    "    batch_xs, batch_ys = mnist.train.next_batch(100)\n",
    "    sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys})\n",
    "\n",
    "# Test trained model\n",
    "correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print(sess.run(accuracy, feed_dict={x: mnist.test.images,\n",
    "                                  y_: mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tutorial tasks\n",
    "- Add logging of the train and validation cross entropy\n",
    "- Add L2 regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework tasks\n",
    "* Add a hidden layer (This turns the model into a neural network)\n",
    "* Add reglarization to the hidden layer\n",
    "* Tune the learning rate and the regularization in order to minimize the loss of the model"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
