{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural network for Boston housing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import sklearn.datasets\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "from ml_course.helpers import sequential_dir\n",
    "\n",
    "sns.set_context(\"poster\")\n",
    "plt.style.use('fivethirtyeight')\n",
    "matplotlib.style.use('fivethirtyeight') \n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "scatter_size = 60\n",
    "\n",
    "boston = sklearn.datasets.load_boston()\n",
    "\n",
    "def feature_normalize(dataset):\n",
    "    mu = np.mean(dataset,axis=0)\n",
    "    sigma = np.std(dataset,axis=0)\n",
    "    return (dataset - mu)/sigma\n",
    "\n",
    "X = feature_normalize(boston.data)\n",
    "Y = boston.target[:, np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-validation split\n",
    "idx_train = np.random.rand(len(X)) < 0.8\n",
    "idx_val = ~idx_train\n",
    "X_train = X[idx_train]\n",
    "Y_train = Y[idx_train]\n",
    "X_val = X[idx_val]\n",
    "Y_val = Y[idx_val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python variables\n",
    "alpha = 0.01\n",
    "learning_rate = 0.01\n",
    "epochs = 500\n",
    "dim_x = X.shape[1]\n",
    "dim_y = Y.shape[1]\n",
    "n_units = [dim_x, 20, 1]\n",
    "\n",
    "# Computation graph\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Input\n",
    "x = tf.placeholder(shape=(None, dim_x), dtype=tf.float32)\n",
    "y = tf.placeholder(shape=(None, dim_y), dtype=tf.float32)\n",
    "x_val = tf.placeholder(shape=(None, dim_x), dtype=tf.float32)\n",
    "y_val = tf.placeholder(shape=(None, dim_y), dtype=tf.float32)\n",
    "\n",
    "with tf.variable_scope('model'):\n",
    "    # Layer 1\n",
    "    with tf.variable_scope('layer1'):\n",
    "        w1 = tf.get_variable(\"W\", shape=(n_units[0], n_units[1]), initializer=random_init)\n",
    "        b1 = tf.get_variable(\"b\", shape=(n_units[1]), initializer=zero_init)\n",
    "        z1 = tf.matmul(x, w1, name=\"z\") + b1\n",
    "        a1 = tf.tanh(z1)\n",
    "\n",
    "    # Layer 2\n",
    "    with tf.variable_scope('layer2'):\n",
    "        w2 = tf.get_variable(\"W\", shape=(n_units[1], n_units[2]), initializer=random_init)\n",
    "        b2 = tf.get_variable(\"b\", shape=(n_units[2]), initializer=zero_init)\n",
    "        z2 = tf.add(tf.matmul(a1, w2), b2, name=\"z\")\n",
    "        y_ = z2    \n",
    "\n",
    "# Evaluation and performance metrics\n",
    "with tf.variable_scope('losses'):\n",
    "    # regularization term\n",
    "    # l2_pentalty = alpha * (tf.nn.l2_loss(w1) + tf.nn.l2_loss(w2)\n",
    "    mss_loss = tf.losses.mean_squared_error(y, y_)\n",
    "    loss = mss_loss\n",
    "    loss_train_summary = tf.summary.scalar('mss_train', loss)\n",
    "    mss_val_summary = tf.summary.scalar('mss_val', mss_loss)\n",
    "    mape = 100 * tf.reduce_mean(tf.abs(tf.div(y_ - y, y)))\n",
    "    mape_train_summary = tf.summary.scalar('mape_train', mape)\n",
    "    mape_val_summary = tf.summary.scalar('mape_val', mape)\n",
    "    summary_train = tf.summary.merge([loss_train_summary, mape_train_summary])\n",
    "\n",
    "# Trainin operators\n",
    "with tf.variable_scope('train'): \n",
    "    random_init = tf.random_uniform_initializer(-0.1, 0.1, dtype=tf.float32)\n",
    "    zero_init = tf.zeros_initializer(dtype=tf.float32)\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    train = optimizer.minimize(loss)\n",
    "    global_init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "logdir = sequential_dir('log/boston_nn', dirname=\"2layers\")\n",
    "print('Storing log files in {}'.format(logdir))\n",
    "filewriter = tf.summary.FileWriter(logdir, graph=sess.graph)\n",
    "global_init.run()\n",
    "y_.eval(feed_dict={x: X_train, y: Y_train})\n",
    "for i in range(epochs):\n",
    "    # Training plus summary\n",
    "    _, train_loss, train_mape, summary_str_train = sess.run([train, loss, mape, summary_train], feed_dict={x: X_train, y: Y_train})\n",
    "    filewriter.add_summary(summary_str_train, global_step=i)\n",
    "    # Validation summary\n",
    "    #summary_str_val = sess.run(summary_val, feed_dict={x: X_val, y: Y_val})\n",
    "    #filewriter.add_summary(summary_str_val, global_step=i)\n",
    "    # Print results to screen\n",
    "    if (i+1)%100==0:\n",
    "        print('epoch: {:4d} loss: {:5.3f} mape: {:3.1f}'.format(i, train_loss, train_mape))\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tutorial Tasks\n",
    "\n",
    "- Add an extra hidden layer with 10 units\n",
    "- Visualize the validation error in TensorBoard\n",
    "- Include regularization for all the layers"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
