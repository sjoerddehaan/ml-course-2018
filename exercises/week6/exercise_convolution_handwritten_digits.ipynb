{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Convolution for handwritten digits\n",
    "\n",
    "In this exercises you investigate the implementation for a convolutional neural network for handwritten digit recognition. Most of the code is already written. Your task is to try to understand the code, write code to train the model and to add extra layers to the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/mnist/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/mnist/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/mnist/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/mnist/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from IPython.display import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "sns.set_context(\"poster\")\n",
    "sns.set_style('white', {'axes.linewidth': 0, 'xtick.major.size': 0.0,\n",
    " 'xtick.minor.size': 0.0, 'ytick.major.size': 0.0,\n",
    " 'ytick.minor.size': 0.0,\n",
    " 'figure.figsize': (10, 6)})\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "\n",
    "\n",
    "data_dir = '/tmp/mnist'\n",
    "mnist = input_data.read_data_sets(data_dir, one_hot=True)\n",
    "train_labels = np.argmax(mnist.train.labels, axis=1)\n",
    "train_images = mnist.train.images.reshape(55000, 28, 28)\n",
    "\n",
    "def view_heatmap(image, label=\"\"):\n",
    "    \"\"\" Plots a grayscale heatmap \"\"\"\n",
    "    if label:\n",
    "        plt.title('Label is {label}'.format(label=label))\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    cur_axes = plt.gca()\n",
    "    cur_axes.axes.get_xaxis().set_visible(False)\n",
    "    cur_axes.axes.get_yaxis().set_visible(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The input images have 28 x 28 pixels\n",
      "The input images have 1 color channel\n"
     ]
    }
   ],
   "source": [
    "image_size = int(np.sqrt(mnist.train.images.shape[1]))\n",
    "image_channels = 1\n",
    "print(\"The input images have {} x {} pixels\".format(image_size, image_size))\n",
    "print(\"The input images have {} color channel\".format(image_channels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshaping input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "# Reshaping of input\n",
    "x = tf.placeholder(tf.float32, [None, 784])\n",
    "x_reshape = tf.reshape(x, [-1, 28, 28, 1])\n",
    "print(x_reshape.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 1: Reshape input\n",
    "1. Explain the shape of `x_reshape`. What is each dimension used for?\n",
    "2. Why do we need to reshape the input?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolutions\n",
    "`tf.nn.conv2d(input, filter, strides, padding)`\n",
    "\n",
    "Given an input tensor of shape `[batch, in_height, in_width, in_channels]`\n",
    "and a filter / kernel tensor of shape\n",
    "`[filter_height, filter_width, in_channels, out_channels]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output layer shape:  (?, 28, 28, 32)\n"
     ]
    }
   ],
   "source": [
    "# Input\n",
    "layer_input = x_reshape\n",
    "in_height = image_size\n",
    "in_width = image_size\n",
    "in_channels = image_channels\n",
    "\n",
    "# Filter dimensions\n",
    "filter_height = 5\n",
    "filter_width = 5\n",
    "out_channels = 32\n",
    "\n",
    "\n",
    "# Convolution parameters\n",
    "# With padding = 'SAME' the \n",
    "stride = 1\n",
    "zero_padding = 0\n",
    "\n",
    "# Derived quantities\n",
    "weight_shape = [filter_height, filter_width, in_channels, out_channels]\n",
    "out_height = (in_height - filter_height + 2*zero_padding)/stride + 1\n",
    "out_width = (in_width - filter_width + 2*zero_padding)/stride + 1\n",
    "\n",
    "\n",
    "with tf.variable_scope('conv_1', reuse=tf.AUTO_REUSE):\n",
    "    random_init = tf.random_normal_initializer(2.0/(filter_height*filter_width*in_channels), dtype=tf.float32)\n",
    "    zero_init = tf.zeros_initializer(dtype=tf.float32)\n",
    "    # Create filter weights\n",
    "    W = tf.get_variable('W', shape=weight_shape, initializer=random_init)\n",
    "    b = tf.get_variable('b', shape=[out_channels])\n",
    "    convolution = tf.nn.conv2d(input=layer_input, filter=W, strides=[1, stride, stride, 1], padding='SAME')\n",
    "    conf1_output = tf.nn.relu(tf.nn.bias_add(convolution, b))\n",
    "    \n",
    "print(\"Output layer shape: \", conf1_output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 2: Strides and padding\n",
    "The padding parameter of `tf.nn.conv2d` is set to 'SAME'. With this setting, `tf.nn.conv2d` uses a padding $p$ that depends on the stride $s$.\n",
    "1. Write down the output dimensions of convolutional layer for stride 1, 2, 3, and 4.\n",
    "1. What is the value of $p$ for $s=1, 2, 3, 4?$ Explain your reasoning.\n",
    "1. Figure out a formula for the padding number $p$ used by `tf.nn.conv2d` if the stride is $s$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Max pooling\n",
    "\n",
    "Change the stride of the convolutional layer back to 1, and re-run that cell. The code cell blow should then output\n",
    "\n",
    "    Output layer shape:  (?, 14, 14, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output layer shape:  (?, 14, 14, 32)\n"
     ]
    }
   ],
   "source": [
    "with tf.variable_scope('pool_1', reuse=tf.AUTO_REUSE):\n",
    "    k = 2\n",
    "    pool1_output = tf.nn.max_pool(conf1_output, ksize=[1, k, k, 1], strides=[1, k, k, 1], padding='SAME')\n",
    "\n",
    "print(\"Output layer shape: \", pool1_output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 3: Max pooling\n",
    "The max pooling operation makes use of padding too. Again we use the setting `padding='SAME'`.\n",
    "1. What is max pooling used for?\n",
    "2. Write down the dimensions for output of the pooling layer for k=2, 3, and 4.\n",
    "2. What padding numbers are being used? Explain your reasoning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fully connected layer\n",
    "\n",
    "Change $k$ in the max pooling layer back to 2, and re-run that cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before sending the output of the pooling layer into the fully connected layer,\n",
    "# we have flatten it.\n",
    "fc_input = tf.reshape(pool1_output, [-1, 14 * 14 * 32])\n",
    "\n",
    "with tf.variable_scope('fc_1', reuse=tf.AUTO_REUSE):\n",
    "    weight_init = tf.random_uniform_initializer(minval=-1, maxval=1, dtype=tf.float32)\n",
    "    bias_init = tf.zeros_initializer()\n",
    "    W = tf.get_variable('W', shape=(14*14*32, 10), initializer=weight_init)\n",
    "    b = tf.get_variable('b', shape=(10), initializer=bias_init)\n",
    "    fc_output = tf.matmul(fc_input, W)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activation function for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_logits = fc_output\n",
    "y_proba = tf.nn.softmax(fc_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss function and minimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = tf.placeholder(name='y', dtype=tf.float32, shape=(None, 10)) # Input of labels\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=y, logits=y_logits))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001)\n",
    "train_op = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variable initializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_var_init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training session\n",
    "\n",
    "\n",
    "#### Problem 4: batch training\n",
    "Create a new session and train the network in a loop over 100 batches. Generate training batches of 64 examples with\n",
    "```\n",
    "batch_x, batch_y = mnist.train.next_batch(64)\n",
    "```\n",
    "Print the training loss at each iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problem 4: session for batch training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacking convolutional layers\n",
    "\n",
    "#### Problem 5: Stacking layers\n",
    "1. After the first pooling layer, add a second convolutoinal layer with 64 filters of  size 5 * 5 and stride 1\n",
    "2. After the second convolutional layer, add a max pooling layer with k=2\n",
    "3. Adapt the fully connected layer to work with the output of the second pooling layer\n",
    "\n",
    "Your code should eventually print \n",
    "\n",
    "    Input shape: (?, 28, 28, 1)\n",
    "    Conf1 output shape:  (?, 28, 28, 32)\n",
    "    Pool1 output shape:  (?, 14, 14, 32)\n",
    "    Conf2 output shape:  (?, 14, 14, 64)\n",
    "    Pool2 output shape:  (?, 7, 7, 64)\n",
    "    Fc_1 output shape:  (?, 10)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (?, 28, 28, 1)\n",
      "Conf_1 output shape:  (?, 28, 28, 32)\n",
      "Pool_1 output shape:  (?, 14, 14, 32)\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "# Reshaping of input\n",
    "x = tf.placeholder(tf.float32, [None, 784])\n",
    "x_reshape = tf.reshape(x, [-1, 28, 28, 1])\n",
    "print(\"Input shape:\", x_reshape.shape)\n",
    "\n",
    "\n",
    "## Convolutional layer 1\n",
    "\n",
    "# Input\n",
    "conf1_input = x_reshape\n",
    "in_height = image_size\n",
    "in_width = image_size\n",
    "in_channels = image_channels\n",
    "\n",
    "# Filter dimensions\n",
    "filter_height = 5\n",
    "filter_width = 5\n",
    "out_channels = 32\n",
    "\n",
    "# Convolution parameters\n",
    "# With padding = 'SAME' the \n",
    "stride = 1\n",
    "zero_padding = 0\n",
    "\n",
    "# Derived quantities\n",
    "weight_shape = [filter_height, filter_width, in_channels, out_channels]\n",
    "\n",
    "\n",
    "with tf.variable_scope('conv_1', reuse=tf.AUTO_REUSE):\n",
    "    random_init = tf.random_normal_initializer(2.0/(filter_height*filter_width*in_channels), dtype=tf.float32)\n",
    "    zero_init = tf.zeros_initializer(dtype=tf.float32)\n",
    "    # Create filter weights\n",
    "    W = tf.get_variable('W', shape=weight_shape, initializer=random_init)\n",
    "    b = tf.get_variable('b', shape=[out_channels])\n",
    "    convolution = tf.nn.conv2d(input=conf1_input, filter=W, strides=[1, stride, stride, 1], padding='SAME')\n",
    "    conf1_output = tf.nn.relu(tf.nn.bias_add(convolution, b))\n",
    "    \n",
    "print(\"Conf_1 output shape: \", conf1_output.shape)\n",
    "\n",
    "with tf.variable_scope('pool_1', reuse=tf.AUTO_REUSE):\n",
    "    k = 2\n",
    "    pool1_output = tf.nn.max_pool(conf1_output, ksize=[1, k, k, 1], strides=[1, k, k, 1], padding='SAME')\n",
    "    print(\"Pool_1 output shape: \", pool1_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Problem 5.1 Add convolutional layer 2 here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Problem 5.2 Add max pooling layer 2 here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fc_1 output shape:  (?, 10)\n"
     ]
    }
   ],
   "source": [
    "## Problem 5.3 Adapt fully connected layer\n",
    "\n",
    "# Before sending the output of the pooling layer into the fully connected layer,\n",
    "# we have to flatten it.\n",
    "fc_input = tf.reshape(pool1_output, [-1, 14 * 14 * 32])\n",
    "\n",
    "with tf.variable_scope('fc_1', reuse=tf.AUTO_REUSE):\n",
    "    weight_init = tf.random_uniform_initializer(minval=-1, maxval=1, dtype=tf.float32)\n",
    "    bias_init = tf.zeros_initializer()\n",
    "    W = tf.get_variable('W', shape=(14*14*32, 10), initializer=weight_init)\n",
    "    b = tf.get_variable('b', shape=(10), initializer=bias_init)\n",
    "    fc1_output = tf.matmul(fc_input, W)\n",
    "    print(\"Fc_1 output shape: \", fc1_output.shape)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
