{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Learning handwritten digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Extracting /tmp/mnist/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Extracting /tmp/mnist/train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting /tmp/mnist/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting /tmp/mnist/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from IPython.display import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "sns.set_context(\"poster\")\n",
    "sns.set_style('white', {'axes.linewidth': 0, 'xtick.major.size': 0.0,\n",
    " 'xtick.minor.size': 0.0, 'ytick.major.size': 0.0,\n",
    " 'ytick.minor.size': 0.0,\n",
    " 'figure.figsize': (10, 6)})\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "\n",
    "\n",
    "data_dir = '/tmp/mnist'\n",
    "mnist = input_data.read_data_sets(data_dir, one_hot=True)\n",
    "train_labels = np.argmax(mnist.train.labels, axis=1)\n",
    "train_images = mnist.train.images.reshape(55000, 28, 28)\n",
    "\n",
    "def view_heatmap(image, label=\"\"):\n",
    "    \"\"\" Plots a grayscale heatmap \"\"\"\n",
    "    if label:\n",
    "        plt.title('Label is {label}'.format(label=label))\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    cur_axes = plt.gca()\n",
    "    cur_axes.axes.get_xaxis().set_visible(False)\n",
    "    cur_axes.axes.get_yaxis().set_visible(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Do you recognize this number?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f383c420080>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "view_heatmap(255 - train_images[1]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Common algorithms\n",
    "* K-nearest neighbours (next lecture)\n",
    "* **Multi class logistic regression**\n",
    "* Fully connected neural network network\n",
    "* Convolutional neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi class logistic regression\n",
    "\n",
    "![](img/softmax-regression-scalargraph.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The multi class logistic regression model generalizes logistic regression to multiple classes.  \n",
    "The model hypothesis of multi class logistic regression with $C$ classes is\n",
    "$$\n",
    "\\begin{align}\n",
    "h_\\theta(X) &= X \\theta \\,, \\\\\n",
    "z &= X \\theta + \\theta_0 \\,, \\\\ \n",
    "g_j(z) &= \\frac{e^{z_j}}{\\sum_{k=1}^C e^{z_k}} \\,.\n",
    "\\end{align}\n",
    "$$\n",
    "The activation function of the output layer is called \"softmax function\". It ensures that the model satisfies the following constraints:\n",
    "$$\n",
    "\\begin{align}\n",
    "& 0 \\leq  h_{\\theta, j}(X) \\leq 1 \\,, \\\\\n",
    "& \\sum_{j=1}^C h_{\\theta, j}(X) \\leq 1 = 1\\,. \\\\\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "A suitable loss function for multi class classification, is cross entropy\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "& J(\\theta) = -\\sum_{i=1}^N \\sum_{j=1}^C y_i \\log(h_{j,\\theta}(x_i) \\,.\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "In this tutorial we are going to implement and train this model with TensorFlow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi class logistic regression\n",
    "1. Create the multi class logistic model\n",
    "    - Compute the logits (input of the softmax function)\n",
    "1. Define a loss function and optimizer\n",
    "    - use `tf.nn.softmax_cross_entropy_with_logits_v2` for the loss\n",
    "1. Create a session and train the model\n",
    "1. Calculate the model performance on the train set\n",
    "    - Add a node for binary predictions to the graph (use `tf.equal` and `tf.argmax`)\n",
    "    - Add a node for probability predictions to the graph\n",
    "    - Add a node for the prediction accuracy\n",
    "1. Calculate the model performance (accuracy) on the validation set\n",
    "1. Add logging for the loss function (train)\n",
    "1. Add logging for the accuracy (train, validation)\n",
    "1. Check the computation graph in TensorBoard\n",
    "1. Use `tf.variable_scope()` to organize the computation graph\n",
    "1. Add a hidden layer\n",
    "1. Wrap layer creation into a function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python variables\n",
    "n_iter = 1000\n",
    "\n",
    "# Softmax model\n",
    "\n",
    "\n",
    "# Loss and optimizer\n",
    "\n",
    "# Create session\n",
    "\n",
    "# Model training\n",
    "for _ in range(n_iter):\n",
    "    batch_xs, batch_ys = mnist.train.next_batch(100)\n",
    "    pass\n",
    "\n",
    "# Model evaluation\n",
    "# print(sess.run(accuracy, feed_dict={x: mnist.test.images,\n",
    "#                                  y_: mnist.test.labels}))"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
